<!DOCTYPE html>
<html lang="en">
  <head>
    <title>The Reasonable Programmer</title>
    <meta charset="UTF-8" />
    <meta
      name="description"
      content="Jason Olson's lifelong journey of code, music, art, and family"
    />
    
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />
    <link rel="stylesheet" href="/tufte.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <style type="text/css">
      html,
      body {
        height: 100%;
      }

      body {
        display: flex;
        flex-direction: column;
        margin: 0;
      }

      #site-header {
        height: 150px;
        background-image: url("/img/site-header.jpg");
        display: flex;
        flex-direction: row;
        align-items: flex-start;
        border: 1px solid black;
        padding: 10px;
      }

      .headshot {
        border: 1px solid #333333;
        border-radius: 50%;
        height: 150px;
        width: 150px;
      }

      #titles {
        padding-left: 20px;
        height: 100%;
        display: flex;
        flex-direction: column;
        justify-content: center;
      }

      .site-title {
        font-size: 2.7rem;
        font-weight: bold;
        color: #eeeeee;
        padding-bottom: 6px;
      }

      .site-subtitle {
        font-size: 1.6rem;
        font-style: italic;
        color: #e1e1e1dd;
      }

      #site-nav {
        display: flex;
        flex-direction: row;
        background-color: #242424;
        padding: 10px;
        font-family: Verdana, Geneva, Tahoma, sans-serif;
        text-transform: uppercase;
      }

      #site-nav > div {
        color: #e1e1e1;
        padding: 0px 10px;
      }

      #site-content {
        flex: 1 0 auto;
        padding: 10px;
      }

      #site-footer {
        padding: 10px;
        color: #888888;
        font-family: Verdana, Geneva, Tahoma, sans-serif;
        font-size: small;
        font-style: italic;
        display: flex;
        justify-content: center;
        flex-shrink: 0;
      }
    </style>
  </head>
  <body>
    <header id="site-header">
      <img
        class="headshot"
        src="/img/headshot.jpg"
        alt="Jason Olson's headshot, a medium age age with glasses, long hair, and a long bear."
      />
      <div id="titles">
        <div class="site-title">The Reasonable Programmer</div>
        <div class="site-subtitle">
          Jason Olson's lifelong journey of code, music, art, and family
        </div>
      </div>
    </header>
    <nav id="site-nav">
      <div><a href="/index.html">Home</a></div>
      <div>|</div>
      <div><a href="/blog.html">Blog</a></div>
      <div>|</div>
      <div><a href="/contact.html">Contact</a></div>
      <div>|</div>
      <div><a href="/index.html">About</a></div>
    </nav>
    <article id="site-content" style="padding: 2rem 0rem"><h1>
  <a href="blog/isolate-for-lack-of-change.html">Isolating For Lack of Change Versus Complexity</a>
</h1>
<section>
  <figure>
    <img
      src="/img/blog/working-with-vintage.jpg"
      alt="A geek that loves classic and vintage computers is working at their workbench dissecting the existing personal computer they are restoring. They are surrounded by shelves of running computers that they've previously restored."
    />
  </figure>
  <p>
    <span class="marginnote">Last Updated: November 12th, 2023</span>
    <em>
      NOTE: This is one of many different lenses through which to look at software design.
      This article outlines some thoughts I've been throwing around in my noggin' as I experiment with different
      approaches and reasons to split software elements out from each other as a piece of software
      grows. These thoughts were formulated working on above-average-to-small code bases. The applicability
      of the discussion will vary on the size of the problem space and granularity level you are working
      at. It is not meant to apply to the extremely large areas, the Googles, the Microsofts, the Amazons.
    </em>
  </p>
  <p>
    I think we may get something wrong as engineers. How many times do we isolate sources of
    complexity off into their own corners? Their own functions, their own classes, their own
    microservices. "Oh, this is going to be changing a lot, split it off into its own thing so it
    can change without impacting other systems". This feels natural and intuitive. But I'm not
    sure it's the logical choice.
  </p>
  <p>
    I personally find that I don't want to isolate my complexity any more. An important skill in
    writing software is managing complexity. The more features that are added to a piece of software,
    the more complex it naturally becomes. If you don't keep this complexity in check, you can find it
    becomes more expensive to add features to your software as time passes.
  </p>
  <p>
    So I try not to isolate my complexity. I have found that I like to see my complexity up front
    and center in my code. For the areas of my code that are a bit intertwined or need to change rapidly,
    I want to have all that code close at hand to me and easy and quick to change.
  </p>
</section>
<section>
  <h2>Optimizing for Change</h2>
  <p>
    It is cheaper to change things that are grouped locally together. It's much simpler to change the
    structure of a couple variables within a single function than change the structure of several
    domain objects returned from different API endpoints across several different API services.
  </p>
  <p>
    Don't get me wrong. I don't believe microservices are inherently a Bad Thing. I have just come to feel
    that it's best to leverage them to "spin off" cohesive elements of your software whose requirements have
    stopped evolving and whose rate of change has settled down. As this code has shown it needs to change
    much less frequently, we can spin it off so it can just plug away doing it's job. For us, it can be
    out-of-sight, out-of-mind as we continue to ship feature after feature in our software.
  </p>
  <p>
    This in turn reduces the concepts that developers need to keep in their mind when working in the core of
    the code that changes. By reducing the total critical mass of the changing code, the code can become
    easier to change as well as there is less stuff for all your software elements to collide against or
    be interfered with.
  </p>
</section>
<section>
  <figure>
    <img
      src="/img/blog/fractal-colorful.jpg"
      alt="A colorful fractal that is reflected above a digital floor with lines of colors on an uneven grid."
    />
  </figure>
  <p>
    <span class="newthought">As software design is fractal</span>, this same concept applies in the small as well. Modules, down to Functions, are 
    great for isolating out the cohesive elements of your code as their change rate "cools down" and the code
    starts to need to change less often.
  </p>
  <p>
    At different times during the life of a piece of software, the same piece of code may rotate in and out of
    the "hot spot" of change. It might become dormant for a while and solidify itself off into a corner. You
    might then get new features coming in that require that element to start changing again. So you might inline
    the code again, allowing it to change structure and evolve to accept the new features into the software.
  </p>
  <p>
    Give it a try! You can practice at nearly any level you are working on. Try to get a feel for how your ability
    to change code changes based on different software designs when you isolate complexity versus isolate cooled code.
    If you are interested in learning more about how you might better experiment in the small, Kent Beck's latest
    book <a href="https://learning.oreilly.com/library/view/tidy-first/9781098151232/">Tidy First?</a> is a great
    read as usual. Kent Beck hit it out of the park again!
  </p>
</section>
<h1>
  <a href="blog/welcome.html">Welcome to my new blog</a>
</h1>
<section>
  <p>
    <span class="marginnote">Last Updated: October 28th, 2023</span>
    All this time away from blogging. Much too long in fact. So why yet another "new blog"? For the
    longest time, this blog used Jekyll and was hosted with Github Pages. So why the switch?
  </p>
  <p>
    For the last 10-15+ years, I haven't been an active blogger. Blogging became more like an
    occasional family holiday. It really started crawling along around the time I started having
    kids. I would write infrequently enough that every time I came back to blog, I would have to
    spend a bunch of time figuring out Ruby upgrades, Jekyll upgrades, dependencies that had been
    deprecated, etc. It became simply too tiring for me. So the blog died.
  </p>
  <figure>
    <img
      src="/img/blog/i-cant-go-longer.jpg"
      alt="An aging programmer ponders if they're really willing to keep on going."
    />
  </figure>
  <p>
    Recently, I've been on a kick of finally building my own tools and leaning-in to YAGNI (You
    Ain't Gonna Need It). I'm approaching my personal life in a more agile way. I'm learning to do
    what <em>I</em> am motivated to do instead of what I think <em>others want</em> me to do. I'm
    learning to embrace a more scientific and logical mindset and learn by doing, not afraid to run
    a "failed" experiment.
  </p>
  <p>So I started over. New project. Fresh slate. Blank `index.ts`. Deep breathe. Here we go.</p>
  <p>
    The only out-of-the-box piece I'm starting with is
    <a href="https://edwardtufte.github.io/tufte-css/">TufteCSS</a>. Everything else is fresh from
    my own index.ts file. I handcode the HTML for each post (I don't care, I'm a developer for
    goodness sakes). This blog does not use a single external runtime dependency outside of
    TufteCSS. It's just the code I need. No more, no less. A pure static, old-school website.
  </p>
  <p>
    <span class="marginnote">
      <img
        src="/img/blog/forgotten-memories.jpg"
        alt="A row of glass jars all collecting dust as if they haven't been used in years"
      />
      Sometimes it feels like the memories are long gone. Sometimes not. But I always wish I had the
      solid memories that many of my colleagues over the years have had.
    </span>
    You see, I have a horrible memory. I know I'll forget this code. I know I'll need to be able to
    get back up to speed with it quickly. As I'm making my own improvements, I need to know that I
    haven't broken anything. My only guarantee is that I <em>will</em> forgot the details and
    nuances of the code by the next time I work on it.
  </p>
  <p>
    So the site generation is fully covered with automated tests. Yes, I wrote it with Test-Driven
    Development. Not because it's some religious dogma I follow, but because it helps me with my own
    anxiety and poor memory when working with code. Well, and "hacking my brain" with a
    high-frequency positive feedback loop during development. I like my positive reinforcement!
  </p>
  <p>
    There's going to be more to come here. It may not be super frequent at first. But I'm going to
    do what I should have done a long time ago: listen to
    <a href="https://www.hanselman.com/blog/dont-ever-break-a-url-if-you-can-help-it">
      Scott Hanselman's wisdom
    </a>
    and control my own content and URLs. I can't go back now and change that. So here I am building
    up my own brand at my own little corner of the ol' World Wide Web.
  </p>
  <p>
    Like olden times. Each one of my keystrokes in a location I control. Keystrokes preserved and
    with a lifetime that is not tied to the lifetime of social media companies.
  </p>
</section>
<h1>
  <a href="blog/makefiles-comeback.html">It's time for makefiles to make a comeback</a>
</h1>
<section>
  <figure>
    <img
      src="/img/blog/article.jpg"
      alt="An LED-lit computer keyboard sitting ready to be used in front of a monitor displaying code."
    />
  </figure>
  <p>
    <span class="marginnote">Last Updated: September 4th, 2017</span>
    Make and makefiles are lost in the past for many developers, its advantages lost in the stream of tools that
    are constantly reinventing the wheel of building software. It's time we get off that crazy carousel.
  </p>
  <p>
    If you ask many developers the first thing that comes to mind with Make and makefiles, you will likely get
    several answers: C/C++, native projects, huge, archaic, or perhaps even old. Some younger developers that have
    grown up in the JavaScript ecosystem may not have even heard of Make and don't realize the advantages they could
    harvest by using an existing, well-proven, and stable tool. Do we really need to be learning a new task runner
    or build system every 18 months as JavaScript frameworks come and go?
  </p>
  <blockquote>
    <p>
      Those who do not understand Unix are condemned to reinvent it, poorly.
    </p>
    <footer>Henry Spencer, Usenet signature, 1987</footer>
  </blockquote>
</section>
<h2>What does this have to do with modern JavaScript development?</h2>
<section>
  <p>
    It's not uncommon for larger JavaScript-based projects today to use a language that compiles down to JavaScript,
    either for powerful language features or for stronger type checking. We use Browserify to package all our JavaScript
    modules together into a bundle to allow front-end developers to have a more composition-based developer experience
    through modules (like back-end developers have in Node.js). We use LESS or SASS and compile out to CSS the browser
    can understand. We minimize our JavaScript to make the files smaller, resulting in faster downloads and page load times.
  </p>
  <p>
    What do all these things have in common with each other? At their core, they are each about taking a set of input
    files and transforming them into a set of output files. And this is exactly what Make is so incredibly good at.
  </p>
  <p>
    What do makefiles do? Makefiles are simply a declarative way to transform one file (or series of files) into another.
    That's it, it's that simple. It's not specific to C, C++, or even to programming languages. You could just as easily
    use a makefile to transform markdown documentation into shipped HTML files, or to pack important files into a zip/tar
    archive, or do a myriad of other transformations.
  </p>
  <p>
    Thanks to its declarative nature and implementation, Make is able to use makefiles to only run the bare transforms
    needed to reach the final destination format. If a source file hasn't changed since the last transformation, the
    source file doesn't have to be processed again. In larger projects, this is a huge win to speed and a boon to the
    developer experience.
  </p>
</section>
<section>
  <p>
    <span class="newthought">Make first appeared</span> over 40 years ago and a lot of software has been built with it since that time. It's a battle-tested
    and stable piece of software that excels at exactly what it was meant to do: transforming files from a source format
    to a target format, with a very simple and easy-to-understand mechanism for declaring dependencies. It's all
    text-based, doesn't try to solve everything itself, and has a great integration experience through calling out to
    shell scripts. In other words, it is very Unix-like. This is hardly surprising given it's birth within the Unix
    environment.
  </p>
  <p>
    Some developers have had experiences with very complicated and convoluted makefiles in larger projects. But it doesn't
    need to be that way. In fact, it can be quite simple to build an NPM package that is implemented in Typescript (from
    building the source code to packaging the NPM package):
  </p>
  <pre><code class="language-cmake">
PATH := node_modules/.bin:$(PATH)

source_files    := $(wildcard lib/*.ts)
build_files     := $(source_files:lib/%.ts=dist/%.js)
PACKAGE         := build/my-package-1.0.0.tgz

.PHONY: all

all: $(PACKAGE)

$(build_files): $(source_files) package.json
    npm i
    tsc

$(PACKAGE): $(build_files) .npmignore
    @mkdir -p $(dir $@)
    @cd $(dir $@) && npm pack $(CURDIR)
  </code></pre>
  <p>
    Yes, the above example was for building a very small project. But just because the project becomes larger, doesn't
    mean the user experience of Make diminishes. Let's look at an example.
  </p>
  <p>
    At work, I'm currently working on a larger project that is based on AWS Kinesis and Lambda Functions, a
    stream-processing system architecture that is serverless. The “service” is based out of one git repository for
    convenience. But we want easily accessible shared libraries between our different Lambda handlers that can also be
    independently deployed projects. This makes deploying fixes or new functionality into production much quicker and
    with much less overhead than deploying the entire service as one large monolith.
  </p>
  <p>
    Our project structure is inspired by a post by StrongLoop on creating a modular Node.js project structure. Even though
    we are using TypeScript, this structure still definitely applies to us. So we started with the linking and npm scripts
    approach outlined in the blog post.
  </p>
  <p>
    Our project structure ended up looking like this in the abstract:
  </p>
  <pre>
- src
    |- lib
        |- foo
            |- dist
                |- *.js (compiled JavaScript files)
            |- lib
                |- *.ts
            |- package.json
            |- makefile
        |- bar
            |- package.json
            |- makefile
        |- baz
            |- package.json
            |- makefile
    |- handlers
        |- alpha (depends on foo and bar)
            |- package.json
            |- makefile
        |- omega (depends on bar and baz)
            |- package.json
            |- makefile
- package.json
- makefile
  </pre>
</section>
<section>
  <p>
    <span class="newthought">But as the number of modules grew</span> and the different ordering of dependencies started
    cropping up (as they do in larger Enterprise software), this approach quickly became unwieldy and painful. We found
    ourselves with a whole mix of preinstall, postinstall, and prestart scripts. It was very difficult to understand what
    was happening at build time to bootstrap the service. And integrating new sub-projects was a pain. It was also a
    “build everything or nothing” type of solution without us putting in a non-trivial amount of extra work.
  </p>
  <p>
    Before grabbing the latest build hotness like Gulp off the shelf, we decided to take a look at what Make could do for
    this since it's an established tool and this is right up its alley. That decision is what kicked off my growing
    appreciation of Make (and inspired this blog post).
  </p>
  <p>
    Being a larger and growing project, we were naturally concerned about whether our build solution would scale. I
    happen to think that using Make, it most definitely does. And other than the Make quirks you get used to after you
    first use it for a while, I think that a junior developer could integrate their own libraries into this Make process.
  </p>
  <p>
    Here's what a potential makefile for the above project would look like:
  </p>
  <pre><code class="language-cmake">
deps_install    := $(CURDIR)/build/last-install-time
pkg_lib_foo     := $(CURDIR)/build/foo-1.0.0.tgz
pkg_lib_bar     := $(CURDIR)/build/bar-1.0.0.tgz
pkg_lib_baz     := $(CURDIR)/build/baz-1.0.0.tgz
pkg_alpha       := $(CURDIR)/build/alpha-1.0.0.tgz
pkg_omega       := $(CURDIR)/build/omega-1.0.0.tgz

.PHONY: all handlers libs

all: libs handlers

handlers: $(deps_install)
    $(MAKE) -C src/handlers/alpha
    $(MAKE) -C src/handlers/omega

libs:
    $(MAKE) -C src/lib/foo
    $(MAKE) -C src/lib/bar
    $(MAKE) -C src/lib/baz

$(deps_install): $(pkg_lib_foo) $(pkg_lib_bar) $(pkg_lib_baz)
    @if [ "$(pkg_lib_foo)" = "$(findstring $(pkg_lib_foo),$?)" ]; then \
        cd $(CURDIR)/src/handlers/alpha && npm i $(pkg_lib_foo); \
    fi
    @if [ "$(pkg_lib_bar)" = "$(findstring $(pkg_lib_bar),$?)" ]; then \
        cd $(CURDIR)/src/handlers/alpha && npm i $(pkg_lib_bar); \
        cd $(CURDIR)/src/handlers/omega && npm i $(pkg_lib_bar); \
    fi
    @if [ "$(pkg_lib_baz)" = "$(findstring $(pkg_lib_baz),$?)" ]; then \
        cd $(CURDIR)/src/handlers/omega && npm i $(pkg_lib_baz); \
    fi
    @touch $(deps_install)
  </code></pre>
  <p>
    As you can see, it doesn't need to be incredibly complicated. As this is a back-end service, we don't have browserify,
    less, or minification. But it should help paint the picture that even with those additions, it should be pretty
    straightforward.
  </p>
  <p>
    If you make a change to the baz library, only baz is rebuilt and only baz is re-installed into the omega handler
    sub-project. Throw a watcher on this process and your build process becomes more rich and improves the local
    development experience.
  </p>
</section>
<h2>The Upsides</h2>
<section>
  <p>
    One thing I really like about this is that things only run if they need to. You don't even need an incremental compiler
    to make it possible. If source files haven't been updated, there is no need to regenerate the target files. Make knows
    this by comparing the last modified times of the source files compared to the target files. You can see the easy
    integration into existing tools like tsc and npm. I didn't need to wait until a wrapper was created (or to create my
    own wrapper) in a code-based build tool.
  </p>
  <p>
    Another less obvious benefit when comparing Make with code-based build tools like Grunt or Gulp is being declarative vs.
    imperative. You get to focus on the end result (declaring what needs to be done) instead of focusing on how the actual
    work is done.
  </p>
  <p>
    Make is also a standalone tool, so there is no need to bring in a bunch of other code dependencies like code-based task
    runners do. This not only makes the user experience better, but it also means there are fewer ways the software can
    break (e.g. a new version of a dependency that breaks functionality in the core tool).
  </p>
</section>
<h2>The Downsides</h2>
<section>
  <p>
    Yes, it's another tool and language that developers need to learn. But that's what we get paid to do as developers,
    right? We always need to be learning new tools and techniques (or re-learning old tools and techniques in this case :P).
    We accept this forever-learning experience as the latest-and-greatest programming languages or software libraries roll
    out every month.
  </p>
  <p>
    But remember, in this case, we are learning a general tool that we will be to leverage in many different ways for a
    long time. Alton Brown need not worry, this tool is very much a multi-tasker. Make has been around for over 40 years
    and it's not going anywhere anytime soon. Can we say the same about Grunt, Gulp, or the next Task Runner du jour?
  </p>
  <p>
    An accurate concern of using Make historically has been the lack of decent support on Windows. By leveraging Make,
    you were potentially making life more difficult for all your Windows users. That was a non-starter for many projects.
    But with the recent addition of Linux support in Windows and the ongoing change of heart under Satya Nadella's leadership
    at Microsoft, this concern is hopefully a relic of the past. With all the great stuff to be learned from and used in
    Linux, I feel this trend is a major boon to software developers.
  </p>
</section>
<h2>Now is a great time to learn Make</h2>
<section>
  <p>
    So today is a great time to learn and start leveraging Make and makefiles. They are still very much relevant to our
    work today as developers. There's no need for an ever-revolving door of task runners du jour. Don't succumb to the
    build tool treadmill and burn yourself out. Learn a powerful tool you will be able to leverage for a long time and
    isn't going anywhere any time soon.
  </p>
  <p>
    Yes, it's time for Makefiles to make a comeback! Let's do this!
  </p>
</section>
<h1>
  <a href="blog/want-to-be-a-craftsman.html">I want to be a craftsman</a>
</h1>
<section>
  <figure>
    <img
      src="/img/blog/craftsman.jpg"
      alt="A craftsman woodworker sits in front of his workbench working on an early model personal computer."
    />
  </figure>
  <p>
    <span class="marginnote">Last Updated: November 8th, 2015</span>
    Developers have long discussed and debated whether programming is an art, a science, an engineering practice, or 
    something else. I don’t believe in Blacks and Whites. I think programming means different things to different people.
    And programming fulfills different expectations depending on its use.
  </p>
  <p>
    Over the last ten years, I’ve taken quite the winding road as a developer. Before joining Microsoft, I was a back-end
    server developer using C#. I loved writing code. I loved learning how to write better code. I loved reading well written
    code. I loved Design Patterns, and Enterprise Application Architecture, and Test-Driven Development, and all the fancy
    buzzwords at the time. I blogged about these loves. I gave talks about these loves. Then several years later, I got a call that
    started the next phase of my career.
  </p>
  <p>
    Almost on a whim, I joined Microsoft after a recruiter contacted me about an open position. It was like being called up to
    the Big Leagues for me, finally called home to the Mothership. I joined Microsoft as a Technical Evangelist. I blogged and
    shared other people’s technologies. I was talking about the problems other people were having. I later joined Windows as a
    Program Manager. I worked to deliver technologies like the Windows Runtime and cool new video editing APIs. But over time,
    I just found myself less excited. I was at Microsoft for over nine years. Towards the end, I knew it was time for me to
    move on.
  </p>
  <p>
    I felt like I was rapidly losing touch with the development world I once held so dear. I saw many of the cool technologies
    my friends were working with and I found myself wanting to be in their shoes. i had lost my passion. I had lost my fire.
    That feeling of excitement about going to work in the morning? I missed that feeling.
  </p>
</section>
<h2>Getting back to my roots</h2>
<section>
  <p>
    So I started interviewing at different companies. I found a couple that I was extremely excited about and absolutely loved
    the technologies they were using. Through the interview process, I fell in love with my current company and team at Concur.
    They have a great culture, a great group of individuals, and a great set of technologies that are sharpening my tools again
    (and hey, we’re hiring!). I had thought about interviewing at Concur ever since Howard Dierking started talking about the
    work he was doing here. However, I let fear prevent me from taking the leap. “I don’t want to be rejected”. “I’m comfortable
    here at Microsoft”. “I couldn’t possibly find a job as good as this”. “I should be happy here, I’m lucky”. All the usual
    suspects. I finally did take the leap though, and I couldn’t be happier with my decision.
  </p>
  <p>
    Do I regret my time at Microsoft? Not at all. I enjoyed most of my time there. I worked with many great people (too many
    people to list here). I learned a lot from the many managers and coworkers I had over the years. I had many great
    experiences like talking at the //build conference and seeing how large-scale software is made and shipped. Now that I’m
    getting my dev legs back under me, I feel like everything I learned during my time at Microsoft has made me a better
    developer. Being a Program Manager taught me to think critically about technology and to focus on the things that actually
    provide value. The many different projects gave me a well-rounded software education which I will always be thankful for.
  </p>
</section>
<h2>Being A Craftsman</h2>
<section>
  <p>
    Here’s the thing though… I want to be a Craftsman. I need to be creating. I need to be getting my hands
    dirty. I’m inspired by documentaries like <a href="https://www.magpictures.com/jirodreamsofsushi/">Jiro Dreams of Sushi</a>,
    <a href="https://www.youtube.com/watch?v=7708E1bmoxc">Building Without Nails</a>,
    <a href="https://designisonefilm.com/">Design Is One</a>,
    and Helvetica. I’m inspired by developers that use Vim or Emacs and can craft their own customized development
    environment; I love Tim Ewald’s talk on Clojure: <a href="https://www.youtube.com/watch?v=ShEez0JkOFw">Programming with Hand Tools.</a>
    I love “craftsman” programming languages like LISP/Scheme, Clojure, Smalltalk, Self, etc. The things people do with
    creative coding frameworks like Processing, or Cinder, or Open Frameworks absolute amaze me. <a href="https://gmunk.com/">gmunk’s</a>
    work on the interfaces in the movie Oblivion? Jaw-dropping (bonus: I discovered he did the graphics for my favorite
    desktop wallpaper in Windows 10!).
  </p>
  <p>
    I want to touch other people’s lives. I want to share my love for writing code again. I want to be a Code
    Craftsman other people look up to. For others that want to be hackers, or engineers, or scientists, that’s cool.
    But it’s not me.
  </p>
  <p>
    One thing is for sure: it’s <em>great</em> to be back! It’s great to have started the next phase of my career.
    And I can’t wait to see the stuff I’ll be a part of in the years to come.
  </p>
</section></article>
    <footer id="site-footer">&copy;2023, Jason Olson</footer>
    <script>hljs.highlightAll();</script>
  </body>
</html>